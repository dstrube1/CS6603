{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a5abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "2022-10-28 15:46:46.646616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If running for the first time, may need to run one or more of these:\n",
    "# %pip install --upgrade pip\n",
    "# !pip install witwidget\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from witwidget.notebook.visualization import WitWidget, WitConfigBuilder\n",
    "# import tensorflow as tf\n",
    "# import functools\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from IPython.display import Markdown  # , display\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "\n",
    "data = pd.read_csv('bank/bank-full.csv', sep=';')\n",
    "# data.head()\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae76c1",
   "metadata": {},
   "source": [
    "Step 2 - Explore the data by answering the following questions:\n",
    "\n",
    "● Which dataset did you select?\n",
    "\n",
    "● How many observations are in the dataset?\n",
    "\n",
    "● How many variables in the dataset?\n",
    "\n",
    "● Which variables did you select as your dependent variables?\n",
    "\n",
    "● How many and which variables in the dataset are associated with a legally recognized protected\n",
    "class? Of those variables associated with a protected class, what is the associated legal precedence/law it falls under as discussed in the lectures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfdc9237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Portuguese Bank Marketing Data Set\n",
      "45211 observations\n",
      "17 variables\n",
      "Dependent variable(s): y\n",
      "Protected class variables (and associated legal precedence/law):\n",
      "\tage: Age (Age Discrimination in Employment Act of 1967) (over 40)\n",
      "\tmarital: Marital status (Familial status) (Civil Rights Act of 1968)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Dataset: Portuguese Bank Marketing Data Set')\n",
    "print(f\"{data.shape[0]} observations\")\n",
    "print(f\"{data.shape[1]} variables\")\n",
    "print('Dependent variable(s): y')\n",
    "print('Protected class variables (and associated legal precedence/law):')\n",
    "print('''\\tage: Age (Age Discrimination in Employment Act of 1967) (over 40)\n",
    "\\tmarital: Marital status (Familial status) (Civil Rights Act of 1968)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f228d3",
   "metadata": {},
   "source": [
    "Step 3 - Based on your selected dataset, specify an outcome variable, protected attributes, and split the dataset into training and testing sets\n",
    "\n",
    "● Select outcome variable(s) that relates to the creditworthiness of a customer and derive a formula to score each customer based on whether they are an Excellent Credit Risk (i.e. highly likely to pay back a loan) versus Bad Credit Risk (i.e. highly likely to default on loan). Select a range of scores from 0-100 where 100 is the maximum value for Excellent Credit Risk. To compute creditworthiness, you can apply any algorithm or set of calculations on the variables that makes sense to you - you can implement your own ML algorithm (which is perfectly fine), create a mathematical formula (which is the basis of all things AI/ML) or even just close your eyes, throw a dart, and pick a single variable from the dataset.\n",
    "\n",
    "● Select a protected class attribute – i.e. choose an attribute on which the bias can occur, basically the attribute you want to test bias for.\n",
    "\n",
    "● Define an unprivileged group and privileged group– i.e. choose a subset of protected attribute values which are considered unprivileged versus privileged from a fairness perspective (i.e. your unprivileged group would be your historically disadvantaged group of interest).\n",
    "\n",
    "● Randomly split your original dataset into equally-size training and testing sets. How many of each (privileged versus unprivileged) members are in each set?\n",
    "\n",
    "● Provide your results indicating your selected outcome variable/conversion formula, protected class attribute, privileged group, and unprivileged group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd49d2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome variables: \n",
      "\t1- balance: average yearly balance, in euros\n",
      "\t2- job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",etc) \n",
      "\n",
      "Mathematical formula: predicted_score = (((balance / 2) * job_multiplier) / maximum balance) * 100\n",
      "Value of job_multiplier: Every job is ranked and each job is given a multiplier between 2 and 0.1 inclusively\n",
      "If predicted_score < 0, then predicted_score = 0\n",
      "\n",
      "Protected class attribute: Age\n",
      "Unprivileged group: < 40 years old; privileged group: 40+\n",
      "Count of unpriviledged in training data: 11645\n",
      "Count of priviledged in training data: 10960\n",
      "Count of unpriviledged in test data: 11717\n",
      "Count of priviledged in test data: 10889\n"
     ]
    }
   ],
   "source": [
    "# Jobs, arranged in order from assumed most likely to assumed least likely to achieve Excellent Credit Risk.\n",
    "# Jobs ordering is debatable, but I feel confident putting unknown close to 50%, and student just above unemployed.\n",
    "jobs = ['management', 'entrepreneur', 'self-employed', 'admin.', 'retired', 'unknown', \n",
    "        'technician', 'services', 'blue-collar', 'housemaid', 'student', 'unemployed']\n",
    "jobs_values = np.linspace(2, 0.1, 12)\n",
    "# range of scores from 0-100 where 100 is the maximum value for Excellent Credit Risk\n",
    "jobs_dict = {}\n",
    "index = 0\n",
    "for job in jobs:\n",
    "    jobs_dict[job] = jobs_values[index]\n",
    "    index += 1\n",
    "max_balance = data['balance'].max()\n",
    "\n",
    "predicted_score = []\n",
    "\n",
    "for row in data.itertuples():\n",
    "    value = (((row.balance/2) * jobs_dict[row.job]) / max_balance) * 100\n",
    "    if value < 0:\n",
    "        value = 0\n",
    "    predicted_score.append(value)\n",
    "\n",
    "\n",
    "predicted_score_df = pd.DataFrame(predicted_score, columns=['predicted_score'])\n",
    "data = pd.concat([data, predicted_score_df], axis=1)\n",
    "\n",
    "print('Outcome variables: ')\n",
    "print('''\\t1- balance: average yearly balance, in euros\n",
    "\\t2- job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",etc) ''')\n",
    "print('\\nMathematical formula: predicted_score = (((balance / 2) * job_multiplier) / maximum balance) * 100')\n",
    "print('Value of job_multiplier: Every job is ranked and each job is given a multiplier between 2 and 0.1 inclusively')\n",
    "print('If predicted_score < 0, then predicted_score = 0\\n')\n",
    "print('Protected class attribute: Age')\n",
    "print('Unprivileged group: < 40 years old; privileged group: 40+')\n",
    "\n",
    "data['age_group'] = data['age'].map(lambda v: 0 if v < 40 else 1)\n",
    "data['y_number'] = data['y'].map(lambda v: 0 if v == 'no' else 1)\n",
    "\n",
    "sections = [int(.5 * data.shape[0])]\n",
    "data_train, data_test = np.split(data.sample(frac=1, random_state=0), sections)\n",
    "\n",
    "data_train_unprivileged = 0\n",
    "data_train_privileged = 0\n",
    "data_test_unprivileged = 0\n",
    "data_test_privileged = 0\n",
    "\n",
    "for row in data_train.itertuples():\n",
    "    if row.age_group == 0:\n",
    "        data_train_unprivileged += 1\n",
    "    else:\n",
    "        data_train_privileged += 1\n",
    "        \n",
    "for row in data_test.itertuples():\n",
    "    if row.age_group == 0:\n",
    "        data_test_unprivileged += 1\n",
    "    else:\n",
    "        data_test_privileged += 1\n",
    "\n",
    "print('Count of unpriviledged in training data: ' + str(data_train_unprivileged))\n",
    "print('Count of priviledged in training data: ' + str(data_train_privileged))\n",
    "print('Count of unpriviledged in test data: ' + str(data_test_unprivileged))\n",
    "print('Count of priviledged in test data: ' + str(data_test_privileged))\n",
    "\n",
    "# print('Making sure total still totals up correctly: ' + str(data_train_unprivileged + data_train_privileged + data_test_unprivileged + data_test_privileged))\n",
    "# 45211\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700988a8",
   "metadata": {},
   "source": [
    "Step 4 - Graph and compute a default threshold that maximizes profit\n",
    "\n",
    "● Using a histogram, graph the data associated with Creditworthiness (where creditworthiness is on\n",
    "the X-axis and the number of associated customers with that creditworthiness is on the Y-axis)\n",
    "\n",
    "● Compute a threshold for approving a loan (based on credit risk) that tries to maximize profit. Assume that a good credit risk is associated with a creditworthiness score >=X. Highlight the\n",
    "threshold information on the graph.\n",
    "\n",
    "● To compute profits, assume, in this case:\n",
    "\n",
    "o Approved Loan/Good Credit Risk = +10 Profit \n",
    "\n",
    "o Approved Loan/Bad Credit Risk = -5 Profit\n",
    "\n",
    "o Declined Loan/Good Credit Risk = -3 Profit\n",
    "\n",
    "o Decline Loan/Bad Credit Risk = 0 Profit\n",
    "\n",
    "● What is your threshold value? What is the profit based on your threshold value? Compute how many in each group (privileged and unprivileged) received Favorable (i.e. Approved) versus Unfavorable (i.e. Declined) outcomes based on your threshold value. Create a table documenting your results. Note: A Favorable outcome is associated with an Approved Loan. An Unfavorable outcome is associated with a Declined Loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd74a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold value: 0.9\n",
      "Profit with selected threshold: -13,136\n",
      "\n",
      "How many in each group received Favorable versus Unfavorable outcomes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>applied</th>\n",
       "      <th>approved</th>\n",
       "      <th>approval_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11645</td>\n",
       "      <td>2211</td>\n",
       "      <td>0.189867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10960</td>\n",
       "      <td>2739</td>\n",
       "      <td>0.249909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_group  applied  approved  approval_rate\n",
       "0          0    11645      2211       0.189867\n",
       "1          1    10960      2739       0.249909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dependent = 'y'\n",
    "#x_train = data_train.drop(dependent, axis=1).values\n",
    "#y_train = data_train[dependent].values  \n",
    "#x_test = data_test.drop(dependent, axis=1).values\n",
    "#y_test = data_test[dependent].values\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "# x_vals = data_train['predicted_score'].values\n",
    "# Nope, ^that's^ not the right data...\n",
    "x_vals = data_train['y_number'].values\n",
    "ax.hist(x_vals, 5)\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html\n",
    "# https://www.geeksforgeeks.org/plotting-histogram-in-python-using-matplotlib/\n",
    "# https://pythongeeks.org/python-histogram/\n",
    "x_mean = x_vals.mean()\n",
    "ax.axvline(x_mean, color='#FF0000', label='Mean')\n",
    "ax.axvline(.9, color='#00FF00', label='Threshold')\n",
    "# ^Labels don't work as expected^\n",
    "ax.annotate(r\"Mean = {:.3f}\".format(x_mean), xy=(1.05 * x_mean, 0.5), rotation=90)  # , color='#FF0000')\n",
    "ax.annotate('Threshold: 0.9', xy=(0.9, 0), rotation=90)  # , color='#00FF00')\n",
    "# ^Making the annotation the same color as the line doesn't work as well as I'd hoped^\n",
    "ax.set_title('Creditworthiness')\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# threshold = 0.2  # -17,843\n",
    "# threshold = 0.3  # -16,079\n",
    "# threshold = 0.4  # -15,020\n",
    "# threshold = 0.5  # -14,531\n",
    "# threshold = 0.6  # -14,264\n",
    "# threshold = 0.7  # -14,042\n",
    "# threshold = 0.8  # -13,409\n",
    "threshold = 0.9  # -13,136\n",
    "\n",
    "data_train['profit'] = 0\n",
    "data_train['profit'] = data_train.apply(lambda record: 10 \n",
    "                                        if record.y_number == 1 and record.predicted_score >= threshold \n",
    "                                        else record.profit, axis=1)\n",
    "data_train['profit'] = data_train.apply(lambda record: -5 \n",
    "                                        if record.y_number == 1 and record.predicted_score < threshold \n",
    "                                        else record.profit, axis=1)\n",
    "data_train['profit'] = data_train.apply(lambda record: -3 \n",
    "                                        if record.y_number == 0 and record.predicted_score >= threshold \n",
    "                                        else record.profit, axis=1)\n",
    "data_train['profit'] = data_train.apply(lambda record: 0 \n",
    "                                        if record.y_number == 0 and record.predicted_score < threshold \n",
    "                                        else record.profit, axis=1)\n",
    "print('Selected threshold value: ' + str(threshold))\n",
    "print(f\"Profit with selected threshold: {data_train.profit.sum():,.0f}\")\n",
    "\n",
    "data_train['prediction_correct'] = (data_train['predicted_score'] >= threshold) * 1\n",
    "data_prediction_rate = data_train.groupby('age_group', as_index=False).agg(\n",
    "    applied=('prediction_correct', 'count'), approved=('prediction_correct', 'sum'))\n",
    "data_prediction_rate['approval_rate'] = data_prediction_rate['approved'] / data_prediction_rate['applied']\n",
    "print('\\nHow many in each group received Favorable versus Unfavorable outcomes:')\n",
    "display(data_prediction_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9886a02",
   "metadata": {},
   "source": [
    "Step 5 - Compute fairness metric on your training set\n",
    "\n",
    "● Based on your protected class attribute and defined privileged and unprivileged groups, select two\n",
    "different fairness metrics (as defined in either the AI Fairness 360 Toolkit or What-If Tool) and compute the differences between privileged and unprivileged groups in your training set data (Note: You can code up your own mathematical formulations, modify open-source code that wasn’t developed for this course, or use the python functions provided by the Toolkit(s) directly)\n",
    "\n",
    "● For example, if we use Disparate Impact as our fairness metric, we would compute the ratio of the rate of favorable outcome for the unprivileged group to that of the privileged group. The ideal value of this metric is 1.0. A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\n",
    "\n",
    "● Identify which fairness metrics were selected and provide your quantitative results from applying the two different fairness metrics on your training set data using your default threshold (Computed in Step 4). Do any of the differences indicate bias either for or against the unprivileged or privileged group? Graph the result for both fairness metrics (indicating the fair/bias thresholds) and document the results in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88dfcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which fairness metrics were selected: BinaryLabelDatasetMetric & ClassificationMetric\n",
      "\n",
      "Quantitative results from applying the two different fairness metrics: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.013466\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.005661\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.013466\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.005661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 15:47:10.607564: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Fitting AdversarialDebiasing with plain model on training binary label dataset: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2022-10-28 15:47:10.916522: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.741812\n",
      "epoch 1; iter: 0; batch classifier loss: 0.382088\n",
      "epoch 2; iter: 0; batch classifier loss: 0.289632\n",
      "epoch 3; iter: 0; batch classifier loss: 0.240821\n",
      "epoch 4; iter: 0; batch classifier loss: 0.288315\n",
      "epoch 5; iter: 0; batch classifier loss: 0.280850\n",
      "epoch 6; iter: 0; batch classifier loss: 0.211738\n",
      "epoch 7; iter: 0; batch classifier loss: 0.206790\n",
      "epoch 8; iter: 0; batch classifier loss: 0.186076\n",
      "epoch 9; iter: 0; batch classifier loss: 0.192595\n",
      "epoch 10; iter: 0; batch classifier loss: 0.322517\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247943\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280110\n",
      "epoch 13; iter: 0; batch classifier loss: 0.163454\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267718\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257320\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231380\n",
      "epoch 17; iter: 0; batch classifier loss: 0.294339\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260534\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236242\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273689\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250043\n",
      "epoch 22; iter: 0; batch classifier loss: 0.290059\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235995\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175803\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177522\n",
      "epoch 26; iter: 0; batch classifier loss: 0.216302\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200122\n",
      "epoch 28; iter: 0; batch classifier loss: 0.236519\n",
      "epoch 29; iter: 0; batch classifier loss: 0.270788\n",
      "epoch 30; iter: 0; batch classifier loss: 0.260863\n",
      "epoch 31; iter: 0; batch classifier loss: 0.300267\n",
      "epoch 32; iter: 0; batch classifier loss: 0.192539\n",
      "epoch 33; iter: 0; batch classifier loss: 0.256522\n",
      "epoch 34; iter: 0; batch classifier loss: 0.228412\n",
      "epoch 35; iter: 0; batch classifier loss: 0.224828\n",
      "epoch 36; iter: 0; batch classifier loss: 0.268987\n",
      "epoch 37; iter: 0; batch classifier loss: 0.197736\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230881\n",
      "epoch 39; iter: 0; batch classifier loss: 0.287518\n",
      "epoch 40; iter: 0; batch classifier loss: 0.299816\n",
      "epoch 41; iter: 0; batch classifier loss: 0.361564\n",
      "epoch 42; iter: 0; batch classifier loss: 0.296360\n",
      "epoch 43; iter: 0; batch classifier loss: 0.225673\n",
      "epoch 44; iter: 0; batch classifier loss: 0.186485\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367157\n",
      "epoch 46; iter: 0; batch classifier loss: 0.264846\n",
      "epoch 47; iter: 0; batch classifier loss: 0.240399\n",
      "epoch 48; iter: 0; batch classifier loss: 0.232883\n",
      "epoch 49; iter: 0; batch classifier loss: 0.267594\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.018747\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.010672\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.895116\n",
      "Test set: Balanced classification accuracy = 0.622647\n",
      "Test set: Disparate impact = 1.239111\n",
      "Test set: Equal opportunity difference = 0.031851\n",
      "Test set: Average odds difference = 0.019072\n",
      "Test set: Theil_index = 0.097533\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Fitting AdversarialDebiasing with debiased model on training binary label dataset: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.622009; batch adversarial loss: 0.704657\n",
      "epoch 1; iter: 0; batch classifier loss: 0.338121; batch adversarial loss: 0.690875\n",
      "epoch 2; iter: 0; batch classifier loss: 0.362775; batch adversarial loss: 0.694889\n",
      "epoch 3; iter: 0; batch classifier loss: 0.252327; batch adversarial loss: 0.687932\n",
      "epoch 4; iter: 0; batch classifier loss: 0.238463; batch adversarial loss: 0.691917\n",
      "epoch 5; iter: 0; batch classifier loss: 0.215790; batch adversarial loss: 0.692834\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272826; batch adversarial loss: 0.682621\n",
      "epoch 7; iter: 0; batch classifier loss: 0.286591; batch adversarial loss: 0.680614\n",
      "epoch 8; iter: 0; batch classifier loss: 0.174487; batch adversarial loss: 0.689695\n",
      "epoch 9; iter: 0; batch classifier loss: 0.195824; batch adversarial loss: 0.691320\n",
      "epoch 10; iter: 0; batch classifier loss: 0.167978; batch adversarial loss: 0.689026\n",
      "epoch 11; iter: 0; batch classifier loss: 0.250945; batch adversarial loss: 0.685729\n",
      "epoch 12; iter: 0; batch classifier loss: 0.175831; batch adversarial loss: 0.695671\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290695; batch adversarial loss: 0.691577\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248942; batch adversarial loss: 0.695358\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307868; batch adversarial loss: 0.692450\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285820; batch adversarial loss: 0.695103\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246732; batch adversarial loss: 0.692484\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320285; batch adversarial loss: 0.692744\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243069; batch adversarial loss: 0.691745\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204436; batch adversarial loss: 0.691698\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269327; batch adversarial loss: 0.692602\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222434; batch adversarial loss: 0.687126\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203088; batch adversarial loss: 0.687386\n",
      "epoch 24; iter: 0; batch classifier loss: 0.260112; batch adversarial loss: 0.690859\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216926; batch adversarial loss: 0.693618\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196035; batch adversarial loss: 0.694717\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210071; batch adversarial loss: 0.694265\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190369; batch adversarial loss: 0.690395\n",
      "epoch 29; iter: 0; batch classifier loss: 0.225663; batch adversarial loss: 0.693187\n",
      "epoch 30; iter: 0; batch classifier loss: 0.321079; batch adversarial loss: 0.693126\n",
      "epoch 31; iter: 0; batch classifier loss: 0.246032; batch adversarial loss: 0.693300\n",
      "epoch 32; iter: 0; batch classifier loss: 0.244757; batch adversarial loss: 0.694254\n",
      "epoch 33; iter: 0; batch classifier loss: 0.252902; batch adversarial loss: 0.695787\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186485; batch adversarial loss: 0.692312\n",
      "epoch 35; iter: 0; batch classifier loss: 0.247737; batch adversarial loss: 0.693934\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213946; batch adversarial loss: 0.693229\n",
      "epoch 37; iter: 0; batch classifier loss: 0.277517; batch adversarial loss: 0.690271\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261622; batch adversarial loss: 0.692675\n",
      "epoch 39; iter: 0; batch classifier loss: 0.224394; batch adversarial loss: 0.686298\n",
      "epoch 40; iter: 0; batch classifier loss: 0.225113; batch adversarial loss: 0.697525\n",
      "epoch 41; iter: 0; batch classifier loss: 0.217199; batch adversarial loss: 0.690073\n",
      "epoch 42; iter: 0; batch classifier loss: 0.246534; batch adversarial loss: 0.690807\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406173; batch adversarial loss: 0.697058\n",
      "epoch 44; iter: 0; batch classifier loss: 0.298438; batch adversarial loss: 0.692340\n",
      "epoch 45; iter: 0; batch classifier loss: 0.262678; batch adversarial loss: 0.693116\n",
      "epoch 46; iter: 0; batch classifier loss: 0.194230; batch adversarial loss: 0.695272\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203656; batch adversarial loss: 0.694980\n",
      "epoch 48; iter: 0; batch classifier loss: 0.244843; batch adversarial loss: 0.691647\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430169; batch adversarial loss: 0.694808\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.018747\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.010672\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.007498\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.004486\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.895116\n",
      "Test set: Balanced classification accuracy = 0.622647\n",
      "Test set: Disparate impact = 1.239111\n",
      "Test set: Equal opportunity difference = 0.031851\n",
      "Test set: Average odds difference = 0.019072\n",
      "Test set: Theil_index = 0.097533\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.894497\n",
      "Test set: Balanced classification accuracy = 0.668254\n",
      "Test set: Disparate impact = 0.942469\n",
      "Test set: Equal opportunity difference = -0.028777\n",
      "Test set: Average odds difference = -0.016101\n",
      "Test set: Theil_index = 0.088716\n",
      "\n",
      "Do any of the differences indicate bias either for or against the unprivileged or privileged group?\n",
      "A negligible bias was indicated for the privileged group\n"
     ]
    }
   ],
   "source": [
    "# Attempting my fairness metrics demo with code modified from this What-If code origin:\n",
    "# https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/What_If_Tool_Notebook_Usage.ipynb\n",
    "\n",
    "# # Converts a dataframe into a list of tf.Example protos.\n",
    "# def df_to_examples(df, columns=None):\n",
    "#     examples = []\n",
    "#     if columns is None:\n",
    "#         columns = df.columns.values.tolist()\n",
    "#     for index, row in df.iterrows():\n",
    "#         example = tf.train.Example()\n",
    "#         for col in columns:\n",
    "#             if df[col].dtype is np.dtype(np.int64):\n",
    "#                 example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "#             elif df[col].dtype is np.dtype(np.float64):\n",
    "#                 example.features.feature[col].float_list.value.append(row[col])\n",
    "#             elif row[col] == row[col]:\n",
    "#                 example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "#         examples.append(example)\n",
    "#     return examples\n",
    "\n",
    "\n",
    "# # Creates simple numeric and categorical feature columns from a feature spec and a\n",
    "# # list of columns from that spec to use.\n",
    "# #\n",
    "# # NOTE: Models might perform better with some feature engineering such as bucketed\n",
    "# # numeric columns and hash-bucket/embedding columns for categorical features.\n",
    "# def create_feature_columns(columns, feature_spec_internal):\n",
    "#     ret = []\n",
    "#     for col in columns:\n",
    "#         if feature_spec_internal[col].dtype is tf.int64 or feature_spec_internal[col].dtype is tf.float32:\n",
    "#             ret.append(tf.feature_column.numeric_column(col))\n",
    "#         else:\n",
    "#             ret.append(tf.feature_column.indicator_column(\n",
    "#                 tf.feature_column.categorical_column_with_vocabulary_list(col, list(data[col].unique()))))\n",
    "#     return ret\n",
    "\n",
    "\n",
    "# # Creates a Tensorflow feature spec from the dataframe and columns specified.\n",
    "# def create_feature_spec(df, columns=None):\n",
    "#     feature_spec_internal = {}\n",
    "#     if columns is None:\n",
    "#         columns = df.columns.values.tolist()\n",
    "#     for f in columns:\n",
    "#         if df[f].dtype is np.dtype(np.int64):\n",
    "#             feature_spec_internal[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "#         elif df[f].dtype is np.dtype(np.float64):\n",
    "#             feature_spec_internal[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.float32)\n",
    "#         else:\n",
    "#             feature_spec_internal[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "#     return feature_spec_internal\n",
    "\n",
    "\n",
    "# # Parses Tensorflow.Example protos into features for the input function, tf_examples_input_fn.\n",
    "# def parse_tf_example(example_proto, label, feature_spec_internal):\n",
    "#     parsed_features = tf.io.parse_example(serialized=example_proto, features=feature_spec_internal)\n",
    "#     target = parsed_features.pop(label)\n",
    "#     return parsed_features, target\n",
    "\n",
    "\n",
    "# # Tensorflow Examples input function\n",
    "# # An input function for providing input to a model from Tensorflow.Examples\n",
    "# def tf_examples_input_fn(examples, feature_spec_internal, label, mode=tf.estimator.ModeKeys.EVAL, num_epochs=None, batch_size=64):\n",
    "#     def ex_generator():\n",
    "#         for j_index in range(len(examples)):\n",
    "#             yield examples[j_index].SerializeToString()\n",
    "#     dataset = tf.data.Dataset.from_generator(\n",
    "#       ex_generator, tf.dtypes.string, tf.TensorShape([]))\n",
    "#     if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#         dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "#     dataset = dataset.batch(batch_size)\n",
    "#     dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec_internal))\n",
    "#     dataset = dataset.repeat(num_epochs)\n",
    "#     return dataset\n",
    "\n",
    "# # Set list of all columns from the dataset we will use for model input.\n",
    "# input_features = ['balance', 'job']  # outcome_variables\n",
    "# # Turn dataframe into a list of Tensorflow Examples\n",
    "# test_examples = df_to_examples(data_train)\n",
    "# # Create a feature spec for the classifier\n",
    "# feature_spec = create_feature_spec(data_train, None)\n",
    "\n",
    "# # Define and train the classifier\n",
    "# num_steps = 5000\n",
    "# train_inpf = functools.partial(tf_examples_input_fn, test_examples, feature_spec, 'age_group')\n",
    "# classifier = tf.estimator.LinearClassifier(\n",
    "#     feature_columns=create_feature_columns(input_features, feature_spec))\n",
    "# classifier.train(train_inpf, steps=num_steps)\n",
    "\n",
    "# config_builder = WitConfigBuilder(test_examples).set_estimator_and_feature_spec(\n",
    "#     classifier, feature_spec).set_label_vocab(['Under 40', '40+'])\n",
    "# tool_height_in_px = 1000\n",
    "\n",
    "# WitWidget(config_builder, height=tool_height_in_px)\n",
    "# ERROR:\n",
    "# Failed to create view for 'WITView' from module 'wit-widget' with model 'DOMWidgetModel' from module '@jupyter-widgets/base'\n",
    "# TypeError: Class constructor O cannot be invoked without 'new'\n",
    "#     at new i (http://localhost:8888/nbextensions/jupyter-js-widgets/extension.js?v=20221025151747:2:257463)\n",
    "#     at http://localhost:8888/nbextensions/jupyter-js-widgets/extension.js?v=20221025151747:2:742192\n",
    "\n",
    "# What If Tool seems a bit alpha right now. Trying AI Fairness 360 instead...\n",
    "\n",
    "# Starting point:\n",
    "# https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_adversarial_debiasing.ipynb\n",
    "\n",
    "# Note, some functions of AI Fairness 360 require all fields to be numerical, thus non-numerical fields \n",
    "# will have to be converted to numericals and then non-numericals will be removed. Since some fields \n",
    "# are being removed, data is being reset so this can be run multiple times without errors:\n",
    "data = pd.read_csv('bank/bank-full.csv', sep=';')\n",
    "\n",
    "# Make all non-numerical fields numerical, and remove non-numericals:\n",
    "# 1 - y\n",
    "data['y_number'] = data['y'].map(lambda v: 0 if v == 'no' else 1)\n",
    "non_numeric = 'y'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 2 - job\n",
    "job_numbers = []\n",
    "for row in data.itertuples():\n",
    "    job_numbers.append(jobs_dict[row.job])\n",
    "\n",
    "job_numbers_df = pd.DataFrame(job_numbers, columns=['job_numbers'])\n",
    "data = pd.concat([data, job_numbers_df], axis=1)\n",
    "non_numeric = 'job'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 3 - marital\n",
    "data['marital_number'] = data['marital'].map(lambda v: 1 if v == 'married' else 0)\n",
    "non_numeric = 'marital'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 4 - education\n",
    "data['education_number'] = data['education'].map(lambda v: 0 if v == 'unknown' else 1)\n",
    "non_numeric = 'education'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 5 - default\n",
    "data['default_number'] = data['default'].map(lambda v: 0 if v == 'no' else 1)\n",
    "non_numeric = 'default'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 6 - housing\n",
    "data['housing_number'] = data['housing'].map(lambda v: 0 if v == 'no' else 1)\n",
    "non_numeric = 'housing'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 7 - loan\n",
    "data['loan_number'] = data['loan'].map(lambda v: 0 if v == 'no' else 1)\n",
    "non_numeric = 'loan'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 8 - contact\n",
    "data['contact_number'] = data['contact'].map(lambda v: 0 if v == 'unknown' else 1)\n",
    "non_numeric = 'contact'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 9 - month\n",
    "# data['month_number'] = data['month'].map(lambda v: 0 if v == 'unknown' else 1)\n",
    "non_numeric = 'month'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# 10 - poutcome\n",
    "data['poutcome_number'] = data['poutcome'].map(lambda v: 0 if v == 'unknown' else 1)\n",
    "non_numeric = 'poutcome'\n",
    "data = data.drop(non_numeric, axis=1)\n",
    "\n",
    "# Rest of the setup\n",
    "data['age_group'] = data['age'].map(lambda v: 0 if v < 40 else 1)\n",
    "privileged_groups = [{'age_group': 1}]\n",
    "unprivileged_groups = [{'age_group': 0}]\n",
    "protected_attribute_names = ['age_group']\n",
    "\n",
    "sections = [int(.5 * data.shape[0])]\n",
    "data_train, data_test = np.split(data.sample(frac=1, random_state=0), sections)\n",
    "                    \n",
    "def get_time(seconds):\n",
    "    # Modified from my CS 7641 Assignment 2\n",
    "    if int(seconds / 60) == 0:\n",
    "        if int(seconds) == 0 and round(seconds, 3) == 0.0:            \n",
    "            # Close enough to 0 to call it 0\n",
    "            return '0 seconds'\n",
    "        else:\n",
    "            return f\"{round(seconds, 3)} second(s)\"\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    if int(minutes / 60) == 0:\n",
    "        return f\"{minutes} minute(s), and {seconds} second(s)\"\n",
    "    hours = int(minutes / 60)\n",
    "    minutes = int(minutes % 60)\n",
    "    # Assuming this won't be called for any time span greater than 24 hours\n",
    "    return f\"{hours} hour(s), {minutes} minute(s), and {seconds} second(s)\"\n",
    "\n",
    "def df_to_BinaryLabelDataset(df, protected_groups, label_names, favorable_label, unfavorable_label):\n",
    "    # Modified from here:\n",
    "    # https://programtalk.com/python-more-examples/aif360.datasets.BinaryLabelDataset/\n",
    "    # label_names = [y.name], a list of the names of the target column\n",
    "    # https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.BinaryLabelDataset.html\n",
    "    result = BinaryLabelDataset(\n",
    "        df=df, protected_attribute_names=protected_groups,\n",
    "        label_names=label_names, favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# On to the meat of the thing:\n",
    "print('Which fairness metrics were selected: BinaryLabelDatasetMetric & ClassificationMetric\\n')\n",
    "print('Quantitative results from applying the two different fairness metrics: ')\n",
    "start = time.time()\n",
    "\n",
    "binary_label_dataset_train = df_to_BinaryLabelDataset(df=data_train, protected_groups=protected_attribute_names,\n",
    "                                                      label_names=['y_number'], favorable_label=1, unfavorable_label=0)\n",
    "binary_label_dataset_test = df_to_BinaryLabelDataset(df=data_test, protected_groups=protected_attribute_names,\n",
    "                                                     label_names=['y_number'], favorable_label=1, unfavorable_label=0)\n",
    "\n",
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(binary_label_dataset_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown('#### Original training dataset'))\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(binary_label_dataset_test,\n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_orig_test.mean_difference())\n",
    "\n",
    "min_max_scaler = MaxAbsScaler()\n",
    "binary_label_dataset_train.features = min_max_scaler.fit_transform(binary_label_dataset_train.features)\n",
    "binary_label_dataset_test.features = min_max_scaler.transform(binary_label_dataset_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(binary_label_dataset_train,\n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "display(Markdown('#### Scaled dataset - Verify that the scaling does not affect the group label statistics'))\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(binary_label_dataset_test,\n",
    "                                              unprivileged_groups=unprivileged_groups,\n",
    "                                              privileged_groups=privileged_groups)\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_scaled_test.mean_difference())\n",
    "print()\n",
    "\n",
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups=privileged_groups,\n",
    "                                   unprivileged_groups=unprivileged_groups,\n",
    "                                   scope_name='plain_classifier',\n",
    "                                   debias=False,\n",
    "                                   sess=sess)\n",
    "display(Markdown('#### Fitting AdversarialDebiasing with plain model on training binary label dataset: '))\n",
    "# This outputs epochs 0-49:\n",
    "plain_model.fit(binary_label_dataset_train)\n",
    "\n",
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model.predict(binary_label_dataset_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(binary_label_dataset_test)\n",
    "\n",
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown('#### Plain model - without debiasing - dataset metrics'))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train,\n",
    "                                                            unprivileged_groups=unprivileged_groups,\n",
    "                                                            privileged_groups=privileged_groups)\n",
    "\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test,\n",
    "                                                           unprivileged_groups=unprivileged_groups,\n",
    "                                                           privileged_groups=privileged_groups)\n",
    "\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown('#### Plain model - without debiasing - classification metrics'))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(binary_label_dataset_test,\n",
    "                                                          dataset_nodebiasing_test,\n",
    "                                                          unprivileged_groups=unprivileged_groups,\n",
    "                                                          privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" \n",
    "      % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "print()\n",
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "# Learn parameters with debias set to True\n",
    "# https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.inprocessing.AdversarialDebiasing.html\n",
    "debiased_model = AdversarialDebiasing(privileged_groups=privileged_groups,\n",
    "                                      unprivileged_groups=unprivileged_groups,\n",
    "                                      scope_name='debiased_classifier',\n",
    "                                      debias=True,\n",
    "                                      sess=sess)\n",
    "display(Markdown('#### Fitting AdversarialDebiasing with debiased model on training binary label dataset: '))\n",
    "debiased_model.fit(binary_label_dataset_train)\n",
    "\n",
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_model.predict(binary_label_dataset_train)\n",
    "dataset_debiasing_test = debiased_model.predict(binary_label_dataset_test)\n",
    "\n",
    "\n",
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown('#### Plain model - without debiasing - dataset metrics'))\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "\n",
    "# Model - with debiasing - dataset metrics\n",
    "display(Markdown('#### Model - with debiasing - dataset metrics'))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train,\n",
    "                                                          unprivileged_groups=unprivileged_groups,\n",
    "                                                          privileged_groups=privileged_groups)\n",
    "\n",
    "print(\n",
    "    \"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test,\n",
    "                                                         unprivileged_groups=unprivileged_groups,\n",
    "                                                         privileged_groups=privileged_groups)\n",
    "\n",
    "print(\n",
    "    \"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" \n",
    "    % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "# Plain model - without debiasing - classification metrics\n",
    "display(Markdown('#### Plain model - without debiasing - classification metrics'))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" \n",
    "      % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "# Model - with debiasing - classification metrics\n",
    "display(Markdown('#### Model - with debiasing - classification metrics'))\n",
    "classified_metric_debiasing_test = ClassificationMetric(binary_label_dataset_test,\n",
    "                                                        dataset_debiasing_test,\n",
    "                                                        unprivileged_groups=unprivileged_groups,\n",
    "                                                        privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5 * (TPR + TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" \n",
    "      % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())\n",
    "print()\n",
    "\n",
    "# end = time.time()\n",
    "# print('\\nDone in ' + get_time(end - start))\n",
    "\n",
    "print('Do any of the differences indicate bias either for or against the unprivileged or privileged group?')\n",
    "print('A negligible bias was indicated for the privileged group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef59898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
